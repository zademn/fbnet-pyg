{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec7c4ec-1140-47e1-a1c2-a62b1ada4682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from FBNet import Model as FBModel\n",
    "from fbnet_geometric import (\n",
    "    AdaptGraphPooling,\n",
    "    CrossTransformer,\n",
    "    FbacBlock,\n",
    "    FeedbackRefinementNet,\n",
    "    HGNet,\n",
    "    Model,\n",
    "    get_batch,\n",
    ")\n",
    "from torch_geometric.nn import knn, knn_graph\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torchinfo import summary\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda4f507-4e50-4ed3-a66e-3fef6166cfb7",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ff711d-063d-4cdf-b889-f39e6a9597ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b535e051-1322-4ccd-939d-2a33f6161d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_many(clouds: list):\n",
    "    pcds = []\n",
    "    for i, p in enumerate(clouds):\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(\n",
    "            p + i * np.array([3, 0, 0])\n",
    "        )  # shift to see them side by side\n",
    "        pcds.append(pcd)\n",
    "    o3d.visualization.draw_geometries(pcds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38f09bf4-9318-43b6-add8-6e354a411076",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.rand(3, 2048, 3).cuda()\n",
    "p_ = rearrange(p, \"b n c -> (b n) c\")\n",
    "batch = get_batch(p).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de46de3d-8ba4-42af-a713-21dddbc0b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ = torch.rand(3 * 2048, 3).cuda()\n",
    "batch = torch.repeat_interleave(torch.arange(3), 2048).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0715c73-053b-4f51-90aa-cd3ac6e7a205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "Model                                                   --\n",
       "├─HGNet: 1-1                                            --\n",
       "│    └─DynamicEdgeConv: 2-1                             --\n",
       "│    │    └─MaxAggregation: 3-1                         --\n",
       "│    │    └─Sequential: 3-2                             --\n",
       "│    │    │    └─Linear: 4-1                            224\n",
       "│    │    │    └─BatchNorm1d: 4-2                       64\n",
       "│    │    │    └─LeakyReLU: 4-3                         --\n",
       "│    │    │    └─Linear: 4-4                            2,112\n",
       "│    └─AdaptGraphPooling: 2-2                           --\n",
       "│    │    └─SumAggregation: 3-3                         --\n",
       "│    │    └─Sequential: 3-4                             --\n",
       "│    │    │    └─Linear: 4-5                            64\n",
       "│    │    │    └─BatchNorm1d: 4-6                       32\n",
       "│    │    │    └─LeakyReLU: 4-7                         --\n",
       "│    │    │    └─Linear: 4-8                            1,088\n",
       "│    │    └─Sequential: 3-5                             --\n",
       "│    │    │    └─Linear: 4-9                            1,040\n",
       "│    │    │    └─BatchNorm1d: 4-10                      32\n",
       "│    │    │    └─LeakyReLU: 4-11                        --\n",
       "│    │    │    └─Linear: 4-12                           1,088\n",
       "│    │    └─Sequential: 3-6                             --\n",
       "│    │    │    └─Linear: 4-13                           1,040\n",
       "│    │    │    └─BatchNorm1d: 4-14                      32\n",
       "│    │    │    └─LeakyReLU: 4-15                        --\n",
       "│    │    │    └─Linear: 4-16                           51\n",
       "│    └─DynamicEdgeConv: 2-3                             --\n",
       "│    │    └─MaxAggregation: 3-7                         --\n",
       "│    │    └─Sequential: 3-8                             --\n",
       "│    │    │    └─Linear: 4-17                           8,256\n",
       "│    │    │    └─BatchNorm1d: 4-18                      128\n",
       "│    │    │    └─LeakyReLU: 4-19                        --\n",
       "│    │    │    └─Linear: 4-20                           8,320\n",
       "│    └─AdaptGraphPooling: 2-4                           --\n",
       "│    │    └─SumAggregation: 3-9                         --\n",
       "│    │    └─Sequential: 3-10                            --\n",
       "│    │    │    └─Linear: 4-21                           64\n",
       "│    │    │    └─BatchNorm1d: 4-22                      32\n",
       "│    │    │    └─LeakyReLU: 4-23                        --\n",
       "│    │    │    └─Linear: 4-24                           2,176\n",
       "│    │    └─Sequential: 3-11                            --\n",
       "│    │    │    └─Linear: 4-25                           2,064\n",
       "│    │    │    └─BatchNorm1d: 4-26                      32\n",
       "│    │    │    └─LeakyReLU: 4-27                        --\n",
       "│    │    │    └─Linear: 4-28                           2,176\n",
       "│    │    └─Sequential: 3-12                            --\n",
       "│    │    │    └─Linear: 4-29                           2,064\n",
       "│    │    │    └─BatchNorm1d: 4-30                      32\n",
       "│    │    │    └─LeakyReLU: 4-31                        --\n",
       "│    │    │    └─Linear: 4-32                           51\n",
       "│    └─DynamicEdgeConv: 2-5                             --\n",
       "│    │    └─MaxAggregation: 3-13                        --\n",
       "│    │    └─Sequential: 3-14                            --\n",
       "│    │    │    └─Linear: 4-33                           32,896\n",
       "│    │    │    └─BatchNorm1d: 4-34                      256\n",
       "│    │    │    └─LeakyReLU: 4-35                        --\n",
       "│    │    │    └─Linear: 4-36                           33,024\n",
       "│    └─Sequential: 2-6                                  --\n",
       "│    │    └─Linear: 3-15                                262,656\n",
       "│    │    └─LeakyReLU: 3-16                             --\n",
       "│    │    └─Linear: 3-17                                262,656\n",
       "│    │    └─LeakyReLU: 3-18                             --\n",
       "│    │    └─Linear: 3-19                                196,992\n",
       "├─FeedbackRefinementNet: 1-2                            --\n",
       "│    └─ModuleList: 2-7                                  --\n",
       "│    │    └─FbacBlock: 3-20                             --\n",
       "│    │    │    └─DynamicEdgeConv: 4-37                  2,400\n",
       "│    │    │    └─MLP: 4-38                              20,896\n",
       "│    │    │    └─CrossTransformer: 4-39                 3,424\n",
       "│    │    │    └─NodeShuffle: 4-40                      2,672\n",
       "│    │    │    └─MLP: 4-41                              6,723\n",
       "│    │    │    └─Upsample: 4-42                         --\n",
       "│    │    └─FbacBlock: 3-21                             --\n",
       "│    │    │    └─DynamicEdgeConv: 4-43                  2,400\n",
       "│    │    │    └─MLP: 4-44                              20,896\n",
       "│    │    │    └─CrossTransformer: 4-45                 3,424\n",
       "│    │    │    └─NodeShuffle: 4-46                      5,312\n",
       "│    │    │    └─MLP: 4-47                              6,723\n",
       "│    │    │    └─Upsample: 4-48                         --\n",
       "│    │    └─FbacBlock: 3-22                             --\n",
       "│    │    │    └─DynamicEdgeConv: 4-49                  2,400\n",
       "│    │    │    └─MLP: 4-50                              20,896\n",
       "│    │    │    └─CrossTransformer: 4-51                 3,424\n",
       "│    │    │    └─NodeShuffle: 4-52                      5,312\n",
       "│    │    │    └─MLP: 4-53                              6,723\n",
       "│    │    │    └─Upsample: 4-54                         --\n",
       "│    └─Rearrange: 2-8                                   --\n",
       "├─Rearrange: 1-3                                        --\n",
       "================================================================================\n",
       "Total params: 934,367\n",
       "Trainable params: 934,367\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model().cuda()\n",
    "summary(model, depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c6104d0-4f33-44b7-8b6e-01f21c9e5272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "Model                                                   --\n",
       "├─HGNet: 1-1                                            820,742\n",
       "├─FeedbackRefinementNet: 1-2                            113,625\n",
       "├─Rearrange: 1-3                                        --\n",
       "================================================================================\n",
       "Total params: 934,367\n",
       "Trainable params: 934,367\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a60d5115-5695-46e7-a526-20a53a45c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_pcd, pcds, _ = model(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e187ad6-6298-4853-959d-3174fc05d187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 128, 3]), torch.Size([3, 2048, 3]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_pcd.shape, pcds[-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e1040f-cfb0-49bb-8393-423be4986e89",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2daec23-2c0e-4e1d-a75f-8bc05598a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "class MvpDataset(data.Dataset):\n",
    "    def __init__(self, prefix=\"train\"):\n",
    "        if prefix == \"train\":\n",
    "            self.file_path = \"./data/MVP_Train_CP.h5\"\n",
    "        elif prefix == \"val\":\n",
    "            self.file_path = \"./data/MVP_Test_CP.h5\"\n",
    "        elif prefix == \"test\":\n",
    "            self.file_path = \"./data/MVP_ExtraTest_Shuffled_CP.h5\"\n",
    "        else:\n",
    "            raise ValueError(\"ValueError prefix should be [train/val/test] \")\n",
    "\n",
    "        self.prefix = prefix\n",
    "\n",
    "        input_file = h5py.File(self.file_path, \"r\")\n",
    "        self.input_data = np.array(input_file[\"incomplete_pcds\"][()])\n",
    "\n",
    "        print(self.input_data.shape)\n",
    "\n",
    "        if prefix != \"test\":\n",
    "            self.gt_data = np.array(input_file[\"complete_pcds\"][()])\n",
    "            self.labels = np.array(input_file[\"labels\"][()])\n",
    "\n",
    "            print(self.gt_data.shape, self.labels.shape)\n",
    "            c_idxs = np.where((self.labels == 0) | (self.labels == 1))[0]\n",
    "            print(c_idxs)\n",
    "            self.input_data = self.input_data[c_idxs]\n",
    "            self.gt_data = self.gt_data[c_idxs // 26]\n",
    "            self.labels = self.labels[c_idxs]\n",
    "\n",
    "            print(self.gt_data.shape, self.labels.shape)\n",
    "\n",
    "        input_file.close()\n",
    "        self.len = self.input_data.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        partial = torch.from_numpy((self.input_data[index]))\n",
    "\n",
    "        if self.prefix != \"test\":\n",
    "            complete = torch.from_numpy((self.gt_data[index // 26]))\n",
    "            label = self.labels[index]\n",
    "            return label, partial, complete\n",
    "        else:\n",
    "            return partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba497f25-52c2-4df0-9de0-834fbb54d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62400, 2048, 3)\n",
      "(2400, 2048, 3) (62400,)\n",
      "[    0     1     2 ... 10397 10398 10399]\n",
      "(10400, 2048, 3) (10400,)\n"
     ]
    }
   ],
   "source": [
    "dataset = MvpDataset(prefix=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4f2e748-69f0-4a02-90d0-557c6d28bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "pcd, gt = dataset[i][1], dataset[i][2]\n",
    "viz_many([pcd, gt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69a171e6-3af5-4c7e-a70d-861c7ee768e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a6c5736-4fbe-4fac-ba94-3504f5e21c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f649d54c-036e-4a3d-b0a5-a795aba4ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, pcd, gt = dataset[3]\n",
    "# viz_many([pcd, gt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c0a7df-42bc-45ad-8f53-71014bbb2af1",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc5a549b-2d4d-45f1-9ee4-bc72634695fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded compiled 3D CUDA chamfer distance\n"
     ]
    }
   ],
   "source": [
    "from ChamferDistancePytorch.chamfer3D.dist_chamfer_3D import (\n",
    "    chamfer_3DDist as ChamferLoss,\n",
    ")\n",
    "\n",
    "\n",
    "def chamfer_dist(output, gt, return_raw=False):\n",
    "    # https://github.com/wutong16/Density_aware_Chamfer_Distance\n",
    "\n",
    "    # cham_loss = dist_chamfer_3D.chamfer_3DDist()\n",
    "    cham_loss = ChamferLoss()\n",
    "    dist1, dist2, idx1, idx2 = cham_loss(gt, output)\n",
    "    cd_p = (torch.sqrt(dist1).mean(1) + torch.sqrt(dist2).mean(1)) / 2\n",
    "    cd_t = dist1.mean(1) + dist2.mean(1)\n",
    "\n",
    "    res = [cd_p, cd_t]\n",
    "    if return_raw:\n",
    "        res.extend([dist1, dist2, idx1, idx2])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "031f919f-7eb1-4bcb-9db1-576422ecae7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.0513, 0.0519, 0.0520, 0.0514, 0.0506, 0.0514, 0.0510, 0.0512, 0.0511,\n",
       "         0.0520, 0.0515, 0.0508, 0.0509, 0.0510, 0.0509, 0.0509, 0.0519, 0.0518,\n",
       "         0.0508, 0.0515, 0.0511, 0.0516, 0.0506, 0.0506, 0.0498, 0.0515, 0.0504,\n",
       "         0.0514, 0.0510, 0.0512, 0.0502, 0.0515], device='cuda:0',\n",
       "        grad_fn=<DivBackward0>),\n",
       " tensor([0.0061, 0.0063, 0.0062, 0.0061, 0.0060, 0.0061, 0.0061, 0.0060, 0.0061,\n",
       "         0.0063, 0.0062, 0.0060, 0.0060, 0.0060, 0.0060, 0.0061, 0.0062, 0.0062,\n",
       "         0.0060, 0.0062, 0.0061, 0.0062, 0.0059, 0.0060, 0.0058, 0.0062, 0.0059,\n",
       "         0.0061, 0.0060, 0.0060, 0.0058, 0.0062], device='cuda:0',\n",
       "        grad_fn=<AddBackward0>)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points1 = torch.rand(32, 1000, 3).cuda()\n",
    "points2 = torch.rand(32, 2000, 3, requires_grad=True).cuda()\n",
    "\n",
    "chamfer_dist(points1, points2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7005be6d-7764-4978-8663-3a8800d98f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, loss_fn, optimizer):\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_proportion = 0.0\n",
    "    for (i, d) in (t := tqdm(enumerate(trainloader), total=len(trainloader))):\n",
    "        # Extract source and target point clouds and batches\n",
    "        p, gt = d[1].to(device), d[2].to(device)\n",
    "\n",
    "        # Train step\n",
    "        optimizer.zero_grad()\n",
    "        pred_coarse, pred_pcds, _ = model(p)\n",
    "\n",
    "        # Calculate loss\n",
    "        _, cd_t = loss_fn(pred_coarse, gt)\n",
    "        loss = cd_t.mean()\n",
    "        for pcd in pred_pcds:\n",
    "            _, cd_t = chamfer_dist(pcd, gt)\n",
    "            loss += cd_t.mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        t.set_description(f\"loss = {loss:.8f}\")\n",
    "        # t.set_description(f\"loss = {total_loss / ((i+1) * trainloader.batch_size) :.8f}\")\n",
    "    return total_loss / len(trainloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16ba0bd7-d7a3-4687-81ee-10f72aa1fad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Time steps:3\n"
     ]
    }
   ],
   "source": [
    "# model = Model().to(device)\n",
    "fbmodel = FBModel().to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(), lr=0.001, betas=[0.9, 0.999]\n",
    ")\n",
    "loss_fn = chamfer_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9757e6a5-1b05-4965-b830-dd7a770acd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c0702642e9406a8c4568b61d7729ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293a910013584fd8a3608186c9ec7857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 \t train_loss=0.141331\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508cb680c185456da5c72bbffddcd8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m----> 3\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# train_loss = train_w_refiner(model, trainloader, loss_fn, optimizer, alpha=0.5)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train step\u001b[39;00m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m pred_coarse, pred_pcds, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     14\u001b[0m _, cd_t \u001b[38;5;241m=\u001b[39m loss_fn(pred_coarse, gt)\n",
      "File \u001b[0;32m~/.conda/envs/pytorch-310/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Knowledge/faculta-trash/master-ml2022/sem1/RTML/3DVision/PointCompletion/FBNet/fbnet_geometric.py:438\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# feedback refinement stage\u001b[39;00m\n\u001b[1;32m    437\u001b[0m coarse_pcd_dense \u001b[38;5;241m=\u001b[39m to_dense_batch(coarse_pcd, batch\u001b[38;5;241m=\u001b[39mbatch)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 438\u001b[0m res_pcds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefiner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoarse_pcd_dense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m fine \u001b[38;5;241m=\u001b[39m res_pcds[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m coarse_pcd_dense, res_pcds, fine\n",
      "File \u001b[0;32m~/.conda/envs/pytorch-310/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Knowledge/faculta-trash/master-ml2022/sem1/RTML/3DVision/PointCompletion/FBNet/fbnet_geometric.py:382\u001b[0m, in \u001b[0;36mFeedbackRefinementNet.forward\u001b[0;34m(self, pcd, partial)\u001b[0m\n\u001b[1;32m    380\u001b[0m     batch_current \u001b[38;5;241m=\u001b[39m get_batch(pcd)\n\u001b[1;32m    381\u001b[0m     batch_next \u001b[38;5;241m=\u001b[39m get_batch(pcd_next)\n\u001b[0;32m--> 382\u001b[0m     pcd, feat, b_ \u001b[38;5;241m=\u001b[39m \u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpcd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpcd_next\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeat_next\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_current\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_current\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_next\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_next\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m     pcd \u001b[38;5;241m=\u001b[39m to_dense_batch(pcd, batch\u001b[38;5;241m=\u001b[39mb_)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    391\u001b[0m pcd_list\u001b[38;5;241m.\u001b[39mappend(pcd)\n",
      "File \u001b[0;32m~/.conda/envs/pytorch-310/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Knowledge/faculta-trash/master-ml2022/sem1/RTML/3DVision/PointCompletion/FBNet/fbnet_geometric.py:299\u001b[0m, in \u001b[0;36mFbacBlock.forward\u001b[0;34m(self, pcd, pcd_next, feat_next, batch_current, batch_next, return_batch)\u001b[0m\n\u001b[1;32m    289\u001b[0m feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_transformer(\n\u001b[1;32m    290\u001b[0m     pcd,\n\u001b[1;32m    291\u001b[0m     pcd_next,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m     batch_y\u001b[38;5;241m=\u001b[39mbatch_next,\n\u001b[1;32m    296\u001b[0m )\n\u001b[1;32m    298\u001b[0m \u001b[38;5;66;03m# Step 3: Feature Expansion\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m feat, batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodeshuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_current\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# Step 4: Coordinate Generation\u001b[39;00m\n\u001b[1;32m    302\u001b[0m delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_delta(feat)\n",
      "File \u001b[0;32m~/.conda/envs/pytorch-310/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Knowledge/faculta-trash/master-ml2022/sem1/RTML/3DVision/PointCompletion/FBNet/upsample.py:120\u001b[0m, in \u001b[0;36mNodeShuffle.forward\u001b[0;34m(self, x, edge_index, pos, batch, return_batch)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    True - will return the upsampled batch vector.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# if edge_index is None:\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m#     edge_index = knn_graph(x, self.k, batch=batch)\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [N, C] -> [N, r * C]\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# x = self.gcn(x, batch=batch)\u001b[39;00m\n\u001b[1;32m    122\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mps(x, batch\u001b[38;5;241m=\u001b[39mbatch)  \u001b[38;5;66;03m# [N, r * C] -> [r * N, C]\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch-310/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/pytorch-310/lib/python3.10/site-packages/torch_geometric/nn/conv/edge_conv.py:135\u001b[0m, in \u001b[0;36mDynamicEdgeConv.forward\u001b[0;34m(self, x, batch)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     b \u001b[38;5;241m=\u001b[39m (batch[\u001b[38;5;241m0\u001b[39m], batch[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 135\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflip([\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: PairTensor)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    train_loss = train(model, trainloader, loss_fn, optimizer)\n",
    "    # train_loss = train_w_refiner(model, trainloader, loss_fn, optimizer, alpha=0.5)\n",
    "    train_losses.append(train_loss)\n",
    "    # val_loss = evaluate(model, valloader, loss_fn)\n",
    "    # history.val_loss.append(val_loss)\n",
    "    print(f\"{epoch=} \\t {train_loss=:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "040562fc-bf7d-4686-8edd-72939ab38c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "gt_list = []\n",
    "data_dir = Path(\"data\")\n",
    "for _, _, files in os.walk(data_dir / \"partial_input\"):\n",
    "    for file in files:\n",
    "        prefix = file.replace(\".npy\", \"\")\n",
    "        input_file = data_dir / \"partial_input\" / file\n",
    "        gt_file = data_dir / \"gt\" / file\n",
    "\n",
    "        inputs = torch.from_numpy(np.load(input_file)).unsqueeze(0).contiguous()\n",
    "        gt = torch.from_numpy(np.load(gt_file)).unsqueeze(0).contiguous()\n",
    "\n",
    "        input_list.append(inputs)\n",
    "        gt_list.append(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dddc1dd-2cb8-4af1-8938-42c75662c918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62453df3-66ea-4559-a7cf-64170777e7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11a960f360c43dea3d6bda0cb0213e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for X in tqdm(input_list):\n",
    "        X = X.cuda()\n",
    "        _, _, fine = model(X)\n",
    "        preds.append(fine.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82d44662-cebd-4da6-b8d9-19dfa0a860e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "viz_many([input_list[i][0].numpy(), preds[i][0].numpy(), gt_list[i][0].numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d21e4-fbc6-44e0-afef-b944ad53f038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
